# """
# æµ‹è¯•æ–°çš„ä¿å­˜é€»è¾‘ï¼šsave_to_file å‚æ•°é›†æˆåˆ° extract_elements å’Œ highlight_elements
# """
# import os
# import sys

# sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../')))

# from DrissionPage import ChromiumPage, ChromiumOptions
# from src.utils.page_extractor import PageExtractor


# def test_new_save_logic():
#     """æµ‹è¯•æ–°çš„ä¿å­˜é€»è¾‘"""
    
#     print("=" * 60)
#     print("ğŸš€ æµ‹è¯•æ–°çš„ä¿å­˜é€»è¾‘")
#     print("=" * 60)
    
#     options = ChromiumOptions()
#     options.auto_port()
#     page = ChromiumPage(addr_or_opts=options)
    
#     try:
#         # è®¿é—® Wikipedia
#         print("\nğŸŒ æ­£åœ¨æ‰“å¼€ Wikipedia...")
#         page.get('https://www.google.com/')
#         page.wait(2)
        
#         extractor = PageExtractor(page)
        
#         # ===== æµ‹è¯• 1: extract_elements å¸¦ä¿å­˜ =====
#         print("\n" + "=" * 60)
#         print("ğŸ“ æµ‹è¯• 1: extract_elements(save_to_file='extracted.txt')")
#         print("=" * 60)
        
#         elements = extractor.extract_elements(
#             highlight=False, 
#             save_to_file="extracted.txt"
#         )
        
#         print(f"âœ… æå–åˆ° {len(elements)} ä¸ªå…ƒç´ ")
#         print(f"âœ… è¿”å›å€¼ç±»å‹: {type(elements)}")
#         print(f"âœ… ç¬¬ä¸€ä¸ªå…ƒç´ : {elements[0] if elements else 'None'}")
        
#         # éªŒè¯æ–‡ä»¶æ˜¯å¦ç”Ÿæˆ
#         if os.path.exists("extracted.txt"):
#             with open("extracted.txt", 'r', encoding='utf-8') as f:
#                 lines = f.readlines()
#             print(f"\nâœ… æ–‡ä»¶å·²ç”Ÿæˆï¼Œå…± {len(lines)} è¡Œ")
#             print("å‰ 3 è¡Œ:")
#             for line in lines[:3]:
#                 print(f"  {line.strip()}")
#         else:
#             print("\nâŒ æ–‡ä»¶æœªç”Ÿæˆ")
        
#         # ===== æµ‹è¯• 2: extract_elements ä¸ä¿å­˜ =====
#         print("\n" + "=" * 60)
#         print("ğŸ“ æµ‹è¯• 2: extract_elements(save_to_file=None)")
#         print("=" * 60)
        
#         elements2 = extractor.extract_elements(highlight=False, save_to_file=None)
#         print(f"âœ… æå–åˆ° {len(elements2)} ä¸ªå…ƒç´ ï¼ˆä¸ä¿å­˜æ–‡ä»¶ï¼‰")
        
#         # ===== æµ‹è¯• 3: highlight_elements å¸¦ä¿å­˜ =====
#         print("\n" + "=" * 60)
#         print("ğŸ“ æµ‹è¯• 3: highlight_elements(save_to_file='highlighted.txt')")
#         print("=" * 60)
        
#         highlighted = extractor.highlight_elements(save_to_file="highlighted.txt")
        
#         print(f"âœ… é«˜äº®å¹¶è¿”å› {len(highlighted)} ä¸ªå…ƒç´ ")
#         print(f"âœ… è¿”å›å€¼ç±»å‹: {type(highlighted)}")
        
#         # éªŒè¯æ–‡ä»¶æ˜¯å¦ç”Ÿæˆ
#         if os.path.exists("highlighted.txt"):
#             with open("highlighted.txt", 'r', encoding='utf-8') as f:
#                 lines = f.readlines()
#             print(f"\nâœ… æ–‡ä»¶å·²ç”Ÿæˆï¼Œå…± {len(lines)} è¡Œ")
#             print("å‰ 3 è¡Œ:")
#             for line in lines[:3]:
#                 print(f"  {line.strip()}")
#         else:
#             print("\nâŒ æ–‡ä»¶æœªç”Ÿæˆ")
        
#         input("\næŒ‰ Enter é”®æ¸…é™¤é«˜äº®...")
#         extractor.clear_highlight()
        
#         # ===== æµ‹è¯• 4: éªŒè¯ ID ä¸€è‡´æ€§ =====
#         print("\n" + "=" * 60)
#         print("ğŸ“ æµ‹è¯• 4: éªŒè¯ extracted.txt å’Œ highlighted.txt çš„ ID ä¸€è‡´æ€§")
#         print("=" * 60)
        
#         with open("extracted.txt", 'r', encoding='utf-8') as f:
#             extracted_lines = f.readlines()
        
#         with open("highlighted.txt", 'r', encoding='utf-8') as f:
#             highlighted_lines = f.readlines()
        
#         # æå– ID
#         extracted_ids = [line.split(':')[0].strip('[]') for line in extracted_lines[:5]]
#         highlighted_ids = [line.split(':')[0].strip('[]') for line in highlighted_lines[:5]]
        
#         print(f"extracted.txt å‰5ä¸ªID: {extracted_ids}")
#         print(f"highlighted.txt å‰5ä¸ªID: {highlighted_ids}")
        
#         if extracted_ids == highlighted_ids:
#             print("âœ… ID å®Œå…¨ä¸€è‡´ï¼")
#         else:
#             print("âŒ ID ä¸ä¸€è‡´ï¼")
        
#         # ===== æµ‹è¯• 5: æµ‹è¯•æ—§æ–¹æ³•ï¼ˆåº”è¯¥æ˜¾ç¤ºè­¦å‘Šï¼‰=====
#         print("\n" + "=" * 60)
#         print("ğŸ“ æµ‹è¯• 5: æµ‹è¯•åºŸå¼ƒçš„æ–¹æ³•ï¼ˆåº”è¯¥æ˜¾ç¤ºè­¦å‘Šï¼‰")
#         print("=" * 60)
        
#         print("\nè°ƒç”¨ save_to_text_file():")
#         extractor.save_to_text_file("deprecated_test.txt")
        
#         print("\nè°ƒç”¨ save_to_html_file():")
#         extractor.save_to_html_file("deprecated_test.html", brief_mode=True)
        
#         # ===== æµ‹è¯• 6: éªŒè¯å…ƒç´ åŒ…å« index å­—æ®µ =====
#         print("\n" + "=" * 60)
#         print("ğŸ“ æµ‹è¯• 6: éªŒè¯è¿”å›çš„å…ƒç´ åŒ…å« index å­—æ®µ")
#         print("=" * 60)
        
#         for i, element in enumerate(elements[:3]):
#             has_index = 'index' in element
#             index_value = element.get('index', 'N/A')
#             print(f"å…ƒç´  {i}: has_index={has_index}, index={index_value}, tag={element['tag']}")
        
#         if all('index' in el for el in elements[:10]):
#             print("âœ… æ‰€æœ‰å…ƒç´ éƒ½åŒ…å« index å­—æ®µ")
#         else:
#             print("âŒ éƒ¨åˆ†å…ƒç´ ç¼ºå°‘ index å­—æ®µ")
        
#         print("\n" + "=" * 60)
#         print("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
#         print("=" * 60)
        
#         print("\nç”Ÿæˆçš„æ–‡ä»¶:")
#         print("  - extracted.txt (æå–æ—¶ä¿å­˜)")
#         print("  - highlighted.txt (é«˜äº®æ—¶ä¿å­˜)")
#         print("  - deprecated_test.txt (æ—§æ–¹æ³•)")
#         print("  - deprecated_test.html (æ—§æ–¹æ³•)")
        
#         input("\næŒ‰ Enter é”®å…³é—­æµè§ˆå™¨...")
        
#     except Exception as e:
#         print(f"\nâŒ é”™è¯¯: {e}")
#         import traceback
#         traceback.print_exc()
#         input("\næŒ‰ Enter é”®å…³é—­æµè§ˆå™¨...")


# if __name__ == "__main__":
#     test_new_save_logic()

import os
import sys

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../')))

from DrissionPage import ChromiumPage, ChromiumOptions
from src.autoagents_web.utils.page_extractor import PageExtractor

if __name__ == "__main__":
    options = ChromiumOptions()
    options.auto_port()
    page = ChromiumPage(addr_or_opts=options)

    page.get('https://en.wikipedia.org/')

    page.wait(2)
    extractor = PageExtractor(page)

    # #extractor.extract_elements(save_to_file="google_elements.txt")
    extractor.extract_elements(save_to_file="wiki_elements.txt")
    page.wait(10)
    # extractor.print_elements()

    # extractor.print_grouped_selectors()

    # extractor.get_elements_by_tag('input')

    # extractor.get_selector_list()

    # extractor.get_elements()

    # extractor.clear()

    page.quit()
